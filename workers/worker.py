import time
import mysql.connector
import os
import logging
import json
from ultralytics import YOLO

# === –õ–û–ì–ò ===
LOG_DIR = 'logs'
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    filename=os.path.join(LOG_DIR, 'worker.log'),
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

def log_info(msg):
    print(msg)
    logging.info(msg)

def log_error(msg):
    print(msg)
    logging.error(msg)

# === –ö–û–ù–§–ò–ì –ë–î ===
DB_CONFIG = {
    'host': 'localhost',
    'user': 'gleb',
    'port': 8889,
    'password': 'g0f9d8s7A',
    'database': 'parking',
    'autocommit': True
}

# === –ú–û–î–ï–õ–¨ YOLO ===
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ runs/detect/parking_space_model11/weights/best.pt
model = YOLO('runs/detect/parking_space_model/weights/best.pt')

# –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
CONFIDENCE_THRESHOLD = 0.3

# === –§–£–ù–ö–¶–ò–ò ===

def get_connection():
    return mysql.connector.connect(**DB_CONFIG)

def fetch_next_task(cursor):
    cursor.execute("""
        SELECT * FROM ai_requests
        WHERE status = 'queued'
        ORDER BY created_at ASC
        LIMIT 1
    """)
    return cursor.fetchone()

def update_status(cursor, task_id, status):
    cursor.execute("UPDATE ai_requests SET status = %s WHERE id = %s", (status, task_id))

def update_response(cursor, task_id, response, accuracy, time_spent):
    cursor.execute("""
        UPDATE ai_requests
        SET status = 'success', response = %s, accuracy = %s, time = %s
        WHERE id = %s
    """, (response, accuracy, time_spent, task_id))

def update_error(cursor, task_id, error_msg, time_spent):
    cursor.execute("""
        UPDATE ai_requests
        SET status = 'error', response = %s, accuracy = NULL, time = %s
        WHERE id = %s
    """, (error_msg, time_spent, task_id))

def get_upload_path(cursor, upload_id):
    cursor.execute("SELECT path FROM user_uploads WHERE id = %s", (upload_id,))
    row = cursor.fetchone()
    return row['path'] if row else None

def process_task(cursor, task):
    task_id = task['id']
    upload_id = task['upload_id']

    update_status(cursor, task_id, 'processing')

    start_time = time.time()

    upload_path = get_upload_path(cursor, upload_id)
    if not upload_path:
        elapsed = time.time() - start_time
        update_error(cursor, task_id, f"File not found for upload_id {upload_id}", elapsed)
        log_error(f"[Task {task_id}] ‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è upload_id={upload_id}")
        return

    file_path = os.path.join('storage/app/public', upload_path)

    try:
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏
        results = model(file_path, imgsz=640)  # –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å imgsz –¥–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        boxes = results[0].boxes

        # –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã —Ç–∏–ø–∞ "occupied" (class == 0) –∏ "vacant" (class == 1)
        occupied_spots = [b for b in boxes if int(b.cls[0]) == 0]  # –ö–ª–∞—Å—Å 0 ‚Äî —ç—Ç–æ occupied
        vacant_spots = [b for b in boxes if int(b.cls[0]) == 1]    # –ö–ª–∞—Å—Å 1 ‚Äî —ç—Ç–æ vacant

        # –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Å –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        filtered_occupied = [b for b in occupied_spots if float(b.conf[0]) > CONFIDENCE_THRESHOLD]
        filtered_vacant = [b for b in vacant_spots if float(b.conf[0]) > CONFIDENCE_THRESHOLD]

        # –ü–æ–¥—Å—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—Ç (occupied + vacant)
        total_spots = len(filtered_occupied) + len(filtered_vacant)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –∑–∞–Ω—è—Ç—ã—Ö, –Ω–∏ —Å–≤–æ–±–æ–¥–Ω—ã—Ö –º–µ—Å—Ç
        if total_spots == 0:
            elapsed = time.time() - start_time
            update_error(cursor, task_id, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ: –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–∞—Ä–∫–æ–≤–æ—á–Ω—ã–µ –º–µ—Å—Ç–∞", elapsed)
            log_info(f"[Task {task_id}] ‚ö†Ô∏è –ü–∞—Ä–∫–æ–≤–æ—á–Ω—ã–µ –º–µ—Å—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (–Ω–∏ –∑–∞–Ω—è—Ç—ã—Ö, –Ω–∏ —Å–≤–æ–±–æ–¥–Ω—ã—Ö)")
            return

        occupied_count = len(filtered_occupied)
        occupancy_rate = round((occupied_count / total_spots) * 100, 2) if total_spots > 0 else 0

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º bbox + confidence –∫ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–º —Ç–∏–ø–∞–º
        occupied_data = [{
            "confidence": float(b.conf[0]),
            "box": list(map(float, b.xyxy[0]))
        } for b in filtered_occupied]

        vacant_data = [{
            "confidence": float(b.conf[0]),
            "box": list(map(float, b.xyxy[0]))
        } for b in filtered_vacant]

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        detection_summary = json.dumps({
            "occupied_count": occupied_count,
            "vacant_count": len(filtered_vacant),
            "total_spots": total_spots,
            "occupancy_rate": occupancy_rate,
            "occupied_spots": occupied_data,
            "vacant_spots": vacant_data
        })

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        with open(os.path.join(LOG_DIR, f"task_{task_id}_result.json"), "w") as f:
            json.dump(json.loads(detection_summary), f, indent=4)

        elapsed = time.time() - start_time
        update_response(cursor, task_id, detection_summary, occupancy_rate, elapsed)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∏—Ç—É–∞—Ü–∏–∏
        if occupied_count == total_spots:
            log_info(f"[Task {task_id}] ‚úÖ –£—Å–ø–µ—à–Ω–æ: –í—Å–µ {total_spots} –º–µ—Å—Ç –∑–∞–Ω—è—Ç—ã, 100% –∑–∞–ø–æ–ª–Ω–µ–Ω–æ, –∑–∞ {elapsed:.2f}s")
        else:
            log_info(f"[Task {task_id}] ‚úÖ –£—Å–ø–µ—à–Ω–æ: {occupied_count}/{total_spots} –º–µ—Å—Ç –∑–∞–Ω—è—Ç–æ, {occupancy_rate}% –∑–∞–ø–æ–ª–Ω–µ–Ω–æ, –∑–∞ {elapsed:.2f}s")

    except Exception as e:
        elapsed = time.time() - start_time
        update_error(cursor, task_id, str(e), elapsed)
        log_error(f"[Task {task_id}] ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

def main():
    log_info("üöÄ –í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω")
    while True:
        try:
            conn = get_connection()
            cursor = conn.cursor(dictionary=True)

            task = fetch_next_task(cursor)
            if task:
                log_info(f"üì• –ù–∞–π–¥–µ–Ω–∞ –∑–∞–¥–∞—á–∞ ID={task['id']}")
                process_task(cursor, task)
            else:
                time.sleep(2)

        except mysql.connector.Error as db_err:
            log_error(f"üí• –û—à–∏–±–∫–∞ –ë–î: {db_err}")
            time.sleep(5)
        except Exception as err:
            log_error(f"üí• –û–±—â–∞—è –æ—à–∏–±–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞: {err}")
            time.sleep(5)
        finally:
            if conn.is_connected():
                cursor.close()
                conn.close()

if __name__ == "__main__":
    main()